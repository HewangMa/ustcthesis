% !TeX root = ../main.tex

% Research
% → 证明现有方法和技术背景不足以解决你的问题

\chapter{论文相关技术}

本章在后文进入评估系统设计和实现之前介绍一些相关技术原理，旨在建立基本的技术共识。

\section{\tc~静态分析工具及其原理}
\label{sec:\tc~静态分析工具及其原理}
% 工具分类
学术界和工业界在\tc~静态分析领域已做了大量的研究，
开发出了众多静态分析工具，并且发展非常迅速。
如今商业工具有
LDRA Testbed、
Perforce Klocwork、
Parasoft \tc~test、
Synopsys Coverity等；
开源工具有
Flawfinder、
FindBugs、
SonarQube、
Clang-tidy等。
许多公司也在基于一些静态分析框架研究开发属于自己的静态分析工具。

对于如此众多的静态分析工具，
可以根据多个维度进行划分：

\begin{itemize}
	\item 系统建模。
	      系统建模是静态分析工具将真实程序映射为可分析抽象模型的过程，
	      其核心目标是在分析可行性与精度之间取得平衡，
	      不同工具在系统建模阶段对程序语义的抽象程度不同，
	      直接决定了后续分析能力的上限。
	      具体方法包括图结构、自动机、布尔程序、谓词抽象程序等等。
	\item 属性描述。
	      属性描述指静态分析工具对待检测程序性质的形式化表达方式，
	      即工具如何描述要检测的属性，
	      属性描述能力限制了工具能够检测的缺陷“类型空间”。
	      具体来说，通常用有限自动机描述时序安全缺陷、
	      用变量间的数值依赖关系和控制依赖关系精确刻画整数溢出、缓冲区溢出等。
	\item 检测过程。
	      检测过程指静态分析工具在抽象模型上执行分析、
	      推导程序行为并发现潜在缺陷的过程。
	      检测过程的选择直接影响分析的复杂度、可扩展性及误报率。
	      常用的有规则匹配、数据流分析、路径枚举与剪枝、
	      子图同构匹配、自动机求积和符号执行等。
	\item 结果验证。
	      结果验证用于判断分析结果是否为真实缺陷，
	      并通过约束求解或反例分析降低误报，
	      通常与路径敏感分析相结合，
	      在规则驱动型工具中较少使用。
	      通常有基于理论证明器的方法，
	      基于SAT(Satisfiability)求解器的方法等。
\end{itemize}

在不同的检查过程中，静态分析工具都有着不同的方法。
众多工具遵循相同或不同的原理，针对软件缺陷检测提出他们自己的检查方法，
比如下列几个工具在上述维度中的位置如表\ref{tab:position_of_some_tools}所示，
其他工具总能在这四个维度上找到他们的位置。
工具发展非常迅速，一次对现状的分类无法准确描述当前工具的多样。

\begin{table}
	\centering
	\caption
	{部分静态分析工具在四个维度中的位置}
	\label{tab:position_of_some_tools}
	\begin{tabular}{ccccc}
		\hline
		工具         & 系统建模         & 属性描述       & 检测过程     & 结果验证   \\
		\hline
		Flawfinder & 字符串          & 字符串        & 规则匹配     & 无      \\
		% UNO        & 自动机          & 自动机        & 自动机求积    & 无      \\
		Clang-tidy & AST + 局部 CFG & AST 模式语义约束 & 规则匹配     & 无      \\
		CSA        & CFG          & 隐式状态断言     & 路径敏感符号执行 & 理论证明器  \\
		% Saturn     & 布尔程序         & 自动机        & 基于子图     & SAT求解器 \\
		% BLAST      & 谓词抽象程序       & 自动机        & 基于路径     & SAT求解器 \\
		\ldots     & \ldots       & \ldots     & \ldots   & \ldots \\
		\hline
	\end{tabular}
\end{table}

% CFG
控制流图（Control Flow Graph, CFG）指的是一个图结构，
其中节点代表基本块（Basic Block），
基本块指的是一系列连续执行的指令，
中间不会有边，
边代表了指令从一个基本块到另一个基本块的可能跳转。
CFG理论上可以覆盖所有的程序执行路径，
但由于程序结构往往非常复杂，
包含众多分支、循环和函数调用，
分析路径呈指数级别增长，
这就是路径爆炸（Path Explosion）。

% 路径敏感
路径敏感（Path-sensitive）是指工具在检测代码问题时，
能够追踪并区分程序中由条件分支（如 if/else）产生的不同执行路径及其对应的程序状态，从而更准确地判断漏洞或错误，避免了非路径敏感分析容易产生的误报（false positives）和漏报（false negatives），但计算复杂度更高。

% 数据流
数据流分析（Data Flow Analysis）是基于CFG的分析方法，
它定义传递函数来描述状态转移规则，
描述在某个基本块内，
数据流信息如何被单条指令更新。
沿着CFG传播状态信息迭代求解直到收敛，
核心在于追踪程序中数据状态在不同执行路径上的流动和变化，
最终检测代码缺陷或进行程序理解。

% 符号执行
符号执行（Symbolic Execution）技术也基于CFG，
它可以通过分析技术得到让特定区域执行的输入。
它通过使用抽象的符号代替具体值来模拟程序的执行，
当遇到分支语句时，
它会探索每一个分支,
将分支条件加入到相应的路径约束中，
若约束可解，
则说明该路径是可达的。
符号执行的目的是在给定的时间内，尽可能的探索更多的路径。

% AST
AST（Abstract Syntax Tree，抽象语法树） 是静态程序分析的核心数据结构。
它以树状形式表示源代码的语法结构，
由编译器前端（如 Clang、Csc、Babel）将源代码解析产生，
AST 会省去无用的符号，仅保留代码的语义结构。
AST中节点代表代码中的元素，
如 VariableDeclaration（变量声明）、
BinaryExpression（二元表达式）、
IfStatement（If 语句）等，
边代表元素之间的层级关系,
如函数包含语句，语句包含表达式等。

% 以规则为单元
软件行业在实际使用静态分析工具进行检查时，往往以工具规则为单位进行检查，
规则也是直接面向程序的静态分析工具设计时的基本单元。
每个工具都有擅长的缺陷检测领域，它会为此设计多种规则，
每个规则都对应这个领域的某一部分缺陷。
例如开源工具Clang-tidy主要面向的是代码违规、
接口误用等可以通过静态分析推断出的缺陷，
它的规则包括以bugprone-开头的针对易出错代码结构的检查、
以concurrency-开头的与并发编程相关的检查（包括线程、纤维、协程等）等。

% 广义的静态分析的不足
尽管静态分析具备显著的优势，
但也有很多广义上的不足。
首先，静态分析存在理论上的“不可能三角”：
分析资源消耗、分析速度和分析精度三者不可同时达到最佳状态。
基于精准的CFG和数据流分析，
在理论上可以实现精准分析，
但由于路径爆炸的存在，
静态分析工具往往会牺牲一些分析精度，
在“不可能三角”中找到工程化平衡点。
这一限制决定了静态分析工具对代码问题的分析精度有不确定的表现，
在面对企业级的庞大代码库时，
表现出的能力往往是一个复杂的“黑盒”。
其次，静态分析技术在实际应用中也会产生诸如误报率高、
精确度较低、告警合并和处理比较复杂等问题。
最后，为了更好的保障安全，大规模软件在进行静态分析检测的时候，
往往会结合多个工具，
在工具本身的检测精度之外，
还有告警处理、数据整合等问题会影响实际应用效果。

% c/cpp对静态分析工具的分析带来的不足
对\tc~静态分析工具来说，也存在基于语言特性带来的不足。
第一，\tc~语言因其底层操作能力强、资源控制精细、广泛用于企业级大规模软件开发，
因此一次完整的静态分析可能长达若干小时。
第二，由于各种工具的检察原理不同，面对多文件交叉、函数调用层次较深或控制流程复杂的代码时，
各种静态分析工具的检测能力差异尤为显著。
第三，\tc~静态分析工具需要面对内存越界访问、资源泄漏、
空指针访问、\tc~代码规范、以及定制化检查规则，
这些特殊的缺陷往往有特化的触发场景。
特别是面对多文件交叉、函数调用层次较深或控制流程复杂的缺陷场景时，
各种工具的检测能力差异尤为显著。

具体来说，各种工具在面对如下\tc~问题会有明显的检查瓶颈：
\begin{itemize}
	\item 跨文件。
	      跨文件的程序会大幅增加代码的规模，
	      涉及到的全局变量、函数和类的数量众多，这使得分析复杂度呈指数级增长。
	      跨文件调用的上下文可能丢失，如函数的定义和调用在不同文件中，
	      参数的精确值和调用栈的信息很难还原。

	\item 函数调用层数深。
	      调用深层次的函数时，涉及多层函数间的调用关系，增加了解析每层语义的难度。
	      另外，静态分析工具对函数调用通常采用上下文敏感分析，
	      即根据具体的调用点来分析函数行为。
	      如果调用层次过深，则需要追踪调用链中的所有上下文信息，
	      分析过程会更加复杂且容易失去精度。
	      另外在深层调用中，递归分析的复杂度急剧增加，可能无法准确推导出函数最终的影响。

	\item 程序基本块太多。
	      程序基本块是一段线性的程序码，只能从这段程式码开始处进入这段程序。
	      基本块太多会导致路径组合爆炸，在静态分析中，基本块多意味着可能的路径数急剧增加。
	      如果程序中有许多分支和循环，每条路径都需要单独分析，导致路径数量指数增长，
	      进而导致时间和空间开销过大，在不可能三角的平衡下丢失精度。

	\item 指针断链。
	      指针断链指的指针原本指向一个有效的内存地址，
	      但后来所指的内存被释放或失效后，指针依然保持原来的值并试图被访问。
	      分析工具需要在跨函数、跨模块时保持准确的指针追踪，
	      单独分析某一个部分通常无法捕获完整的指针使用语境，
	      导致程序分析工具在面对指针断链问题时展现出不足。

	\item 代码重入次数(max loop num，MLN)太大。
	      大多数静态分析工具在对循环进行检查时，往往使用展开方式，
	      将循环展开 MLN 次，以检查循环代码在重入多次时的安全问题，
	      但该参数对于检查性能来说影响较大，静态分析工具一般将它设置为较小值，
	      对于确保重入代码的安全性来说保障性有待检验。

\end{itemize}

本节介绍了静态分析工具及其基本原理。
总的来说，静态分析工具种类繁多，
但目前静态分析工具仍然有有广阔的优化空间，
为此，对静态分析工具的评估和相关的研究不仅对工具优化至关重要，
也对软件安全有着长远的影响。

\section{静态分析工具评估}

一般来说，对静态分析工具的评估大都使用测试集实测的方式，评估方法如下。

\begin{enumerate}
	\item 明确评估对象与测试集。
	      测试集指的是对工具进行评估时准备的缺陷或测试用例全集。
	      定义被评估的静态分析工具和测试集，设定衡量工具能力的评估指标。
	      例如，测试哪些具体测例文件，并通过哪些标准衡量性能。
	      格式化存储基准测试集中的关键信息，例如文件数量、缺陷类型、注入缺陷位置等，
	      为后续评估过程提供数据支持。

	\item 运行静态分析工具并获取原始结果。
	      利用自动化工具高效批量执行测试，采集分析结果，
	      提高运行效率的同时减少手动操作带来的误差。

	\item 解析结果并计算评估指标。
	      对原始结果中的告警信息进行处理与分类，计算并对比各类评估指标，
	      对工具能力作出全面分析。同时在这一步需要对缺陷具体代码进行归档。
\end{enumerate}

\subsection{测试集}
\label{sec:测试集}

测试集是用于评估静态分析工具的基础内容。
% \textbf{场景}(Scene)描述了缺陷发生的实际条件和路径，一种缺陷可以关联多个场景。
测试集的完整性和复杂性在静态分析工具能力评估中尤为关键，它需要能够体现实际软件的复杂场景。
若测试集包含的缺陷场景有限，
评估结果可能无法反映工具在真实环境中的表现，
导致实际应用中的缺陷频发，
评估系统应该避免这种情况。

常见缺陷枚举(Common Weakness Enumeration，CWE)
是开源社区维护的常见软件与硬件弱点列表，
它并非仅针对静态分析工具，而是涵盖广义的软件缺陷集合。
CWE 共包含 944 种计算机软硬件相关缺陷，
其中软件领域缺陷 399 种，与\tc~相关的缺陷共 118 种。
对于所有缺陷，CWE 从分类层级、基础类型、变量、作用链等多个维度进行组织；
但针对\tc~相关的 CWE 缺陷，本文将这 118 种缺陷视为并列的缺陷集合进行分析。
每个 CWE 缺陷均具有唯一编号，常见的\tc~缺陷包括
\texttt{CWE-126:Buffer\_OverRead}（越界读），
\texttt{CWE-416:Use\_After\_Free}（释放后使用）等。

CWE缺陷仅仅是缺陷分类，
并不能精准的识别到细致的场景，评估粒度不够细。
一个具体的评估测试集选择应该以CWE缺陷为基础，建立场景粒度的测试集。

朱丽叶测试集(Juliet Test Suite，JTS)
是由美国国家安全局(NSA)软件质量中心(CAS)为评估静态分析工具的能力而创建的专用测试集，
它基于CWE缺陷分类，也有自身细化的代码分类。
JTS 由 61387 个测试用例组成，大部分测试用例使用定制测试用例模板引擎生成，
其他部分的测试用例由人工创建而成。
该测试集涵盖了 118 种CWE类型，由 96896 个\tc~文件、867 万行代码构成。

JTS 在行业中取得了一定的成功，
定下了较好的基准，
在很多研究人员的静态分析标准评估流程中都有使用，
但经过研究，JTS也存在如下局限性。

\begin{itemize}
	\item JTS 测试集主要集中于单个文件内的代码缺陷，
	      对于跨文件和跨编译单元的代码缺陷的用例很少，
	      而这种情况恰恰是大型企业级软件的缺陷发生的多数情况。
	\item JTS 测试集是存量代码，
	      对于大型企业级软件中实际发生的问题有其更新机制，
	      但流程较长，更新不及时，
	      且依赖非常多的人力投入。
	\item JTS 测试集并不直接反馈测试人员对某种特定场景的需求，
	      当测试人员需要提供“某工具能否覆盖某种场景的说明和检验”时，
	      需要花较多成本检索或构建。
	      % \item JTS 测试集不能反映研究人员对特定静态分析工具的测试需求，
	      %       某些产品代码中有特殊的定义、规范和检查要求，
	      %       JTS 不能直接反映这些问题的检查精度。
\end{itemize}

Functional类型是JTS在同种CWE缺陷的基础上对缺陷类型的进一步细分。
每个CWE缺陷的 Functional 类型不同，
如果该 CWE 类型没有更细粒度的内容，则 Functional 类型为 basic。
测试用例中使用的数据结构、特殊函数或特殊标记都有可能是 Functional 类型中的关键词。
举例来说，
\texttt{CWE-667:Improper\_Lockin} （加锁不当）这个缺陷，
仅有 basic 作为 Functional 类型;
\texttt{CWE-126:Buffer\_OverRead} （越界读内存）这个缺陷，
包括
\texttt{char\_alloca\_loop}、
\texttt{char\_alloca\_memcpy}、
\texttt{char\_alloca\_memmove}
等多种 Functional 类型。

代码结构复杂度类型(Flow)是JTS设计的代码结构中的数据流类型、控制流类型。
这是另一种对缺陷的分类维度，
更针对静态分析的工具原理，能够对工具的能力进行更细致的划分。
Flow 类型共有48种，用数字标记，
01代表 baseline ，02至30代表控制流，31至84代表数据流，
其中部分列举如表\ref{tab:Meaning_of_some_Flow_types}
JTS使用Functional类型和Flow类型作为文件名，
用以组织测试用例。

\begin{table}
	\centering
	\caption
	{部分Flow类型含义}
	\label{tab:Meaning_of_some_Flow_types}
	\begin{tabular}{ccp{9cm}}
		\hline
		Flow 类型
		 & 所属类别
		 & 该 Flow 类型代码的主要结构特点                                                                                                           \\
		\hline
		02
		 & 控制流
		 & \texttt{if(1) and if(0) }                                                                                                    \\
		08
		 & 控制流
		 & \texttt{if(staticReturnsTrue()) and if(staticReturnsFalse()) }                                                               \\
		14
		 & 控制流
		 & \texttt{if(globalFive==5) and if(globalFive!=5) }                                                                            \\
		18
		 & 控制流
		 & \texttt{goto statements}                                                                                                     \\
		31
		 & 数据流
		 & \texttt{Data flow using a copy of data within the same function}                                                             \\
		33
		 & 数据流
		 & \texttt{Use of a C++ reference to data within the same function }                                                            \\
		65
		 & 控制流、数据流
		 & \texttt{Data passed as an argument from one function to a function in a different source file called via a function pointer} \\
		\ldots
		 & \ldots
		 & \ldots                                                                                                                       \\
		\hline
	\end{tabular}
\end{table}

\subsection{评估指标}
\label{sec:评估指标}

静态分析工具的性能分为很多维度，用对应的指标来表征。
在执行完检查之后，指标通过“有无告警”和“有无缺陷”矩阵数据
表\ref{tab:statistics_of_analysis}来计算。

\begin{table}
	\centering
	\caption
	{静态分析检查得到的数据}
	\label{tab:statistics_of_analysis}
	\begin{tabular}{p{2cm}p{5cm}p{5cm}}
		\hline
		    & 有告警                   & 无告警                   \\
		\hline
		有缺陷 & TP(True Positive，正报)  & FN(False Nagetive，漏报) \\
		无缺陷 & FP(False Positive，误报) & TN(True Nagetive)     \\
		\hline
	\end{tabular}
\end{table}

精确度(Precision)指工具所有告警中实际为缺陷的比例，
其计算方法如公式(\ref{eq:Precision})所示。
精确度回答了“静态分析工具的缺陷告警是否精确”的问题，描述了静态工具的可信程度。
精确度越高，代表静态分析工具给出的告警更有可能确实是缺陷，即该告警的可信度越高。

\begin{equation}
	\text{Precision} = \frac{TP}{TP + FP}
	\label{eq:Precision}
\end{equation}

召回率(Recall)指工具正确告警缺陷占所有缺陷的比例，
其计算方法如公式(\ref{eq:Recall})所示。
召回率回答了“静态分析工具能识别多少缺陷”的问题，
描述了工具告警对于整体缺陷的覆盖程度，反映工具的漏报情况。
召回率越高，代表静态分析工具找到了较多的缺陷，漏报率低。

\begin{equation}
	\text{Recall} = \frac{TP}{TP + FN}
	\label{eq:Recall}
\end{equation}

F1分数(F1)是精确度和召回率的调和平均，为综合指标，
其计算方法如公式(\ref{eq:F1})所示。
F1 分数反映静态分析工具在漏报和误报之间的平衡性。
一个工具如果采用激进策略，选择将所有疑似缺陷都进行告警，
则该工具尽管拥有非常高的召回率，但其精准度会非常低，
在这种情况下，F1 分数可以更好地反映工具的缺陷分析能力。

\begin{equation}
	\text{F1} = \frac{2 * Precision * Recall}{Precision + Recall}
	\label{eq:F1}
\end{equation}

区分度(Discrimination Rate)
被用来评估静态分析工具辨别“有缺陷程序结构”和“无缺陷程序结构”的能力，
其计算方法如公式(\ref{eq:Discrimination})所示。
NSA CAS（美国国家安全局 软件质量中心）引入了“有区分度的正报”这个概念，
即Discriminations，其含义是工具正确地报出某测试用例的“有缺陷函数”，
同时没有错误地报出该测试用例的“无缺陷函数”。
对于这种告警，开发人员再修改正确之后告警会自动消失。

\begin{equation}
	\text{Discrimination} = \frac{Discriminations}{TP + FN}
	\label{eq:Discrimination}
\end{equation}

CWE覆盖度(CWE Coverage)
是工具能够检测的缺陷类数和总缺陷类数的比值，
其计算方法如公式(\ref{eq:CWE_Coverage})所示。
用来评估静态分析工具在缺陷粒度下的覆盖能力。

\begin{equation}
	\text{CWE\_Coverage}
	= \frac{\text{CWE\_Covered}}{\text{CWE\_total}}
	\label{eq:CWE_Coverage}
\end{equation}


Flow覆盖度(Flow Coverage)
是指工具的某一个规则在它所负责的CWE范围中能够检测出的Flow数和总Flow数的比值，
其计算方法如公式(\ref{eq:Flow_Coverage})所示。
用来评估静态分析工具的每个规则在它负责的缺陷下对具体出错类型的覆盖能力。

\begin{equation}
	\text{Flow\_Coverage}
	= \frac{\text{Flow\_Covered}}{\text{Flow\_total}}
	\label{eq:Flow_Coverage}
\end{equation}

% 指标总结todo

其他评估指标还有检查速度、运行时算力消耗、检查功能等等，
与静态分析工具的覆盖能力不直接相关。
本文研究聚焦于评估静态分析工具正确检测软件缺陷的能力，
也就是上述工具的核心评估指标。

本节介绍了用于静态分析工具评估的流程、数据集和指标，
为后文系统化评估提供了基本知识共识，
也启发了更完善的评估方式。

\section{测试集拓展和生成式人工智能}
\label{sec:测试集拓展和生成式人工智能}

用例集的选择、使用及不断扩充，对于静态代码分析工具评估非常重要。
本文在章节\ref{sec:静态分析工具评估的国内外研究现状}部分提到测试集拓展的研究，
他们的研究的优点在于可以根据某些预设的场景进行拓展，
但缺点在于有一些静态分析工具的检查边界依然没有被触及到。
另一方面，这些场景测例没有被系统化的管理起来，
所以针对静态分析工具评估的测例拓展和管理，
需要使用更先进的技术。

随着人工智能（Artificial Intelligence, AI）技术的发展，
未来基于生成式技术的场景生成方法有望帮助测试集的构建，
尤其是检索增强生成技术（Retrieval-augmented generation，RAG），
被广泛应用于问答和生成任务中，
特别是在大规模参考文档场景下，RAG能够有效地整合分散的知识源，
自动生成高质量的内容，
可以启发测试集拓展，
无论是正向梳理，还是被动补充，
都有RAG的用武之地。

LLM 是由具有大量参数的人工神经网络组成的一类语言模型。
目前市面上有海量对LLM的研究，
各种LLM的能力不同，举例来说，
闭源的GPT4o有超强的多模态功能，
可以细腻的感知情绪并回答；
而在代码生成方面，
有LLama3系列、DeekSeek v2系列、Qwen2系列都广为使用。
从目前各家开放的技术报告来看，
对于代码能力谈的都比较宽泛，
涉及细节较少。

RAG 基于大语言模型（large language model，LLM），
RAG 依赖于与用户输入相关的背景知识，
在 LLM 和检索能力的基础上构建索引、检索和生成过程。
索引过程是构建背景知识向量数据库的过程，
它将不同格式的数据统一化，
随后分块并使用嵌入模型储存入向量数据库。
检索过程则是从数据库中提取相关知识的过程，
该过程利用嵌入模型将用户询问向量化，
随后与向量数据库比较相似度，
检索出达到相似度阈值的数据。
检索过程是提升 RAG 表现的关键步骤，
由于 LLM 的知识有限，
从已有数据库中检索出问题所需的知识非常关键，
常用的检索方法包括 BM25 和向量检索，
分别对应精确搜索和自然语言理解搜索。

其中BM25是一种经典的信息检索算法，
用于评估用户查询与文档之间的相关性，
广泛应用于搜索引擎（如Elasticsearch）中，
它改进了传统的TF-IDF，
通过综合考虑词频（TF）、逆文档频率（IDF）以及文档长度等因素来打分，
核心思想是文档包含查询词越多、越罕见（IDF高）且文档不是特别长时，
相关性得分越高。
BM25检索速度不快，
但是可以找到关键词非常相关的内容。
另一方面，
向量检索是一种基于语义相似度而非传统关键词匹配的搜索技术。
通过深度学习模型将非结构化数据转化为一串数字数组（高维向量），
这些数字捕捉了数据的内在语义特征。
在检索时将查询请求也转化为向量，
在多维向量空间中计算查询向量与已知数据向量之间的“距离”，
常用距离包括余弦相似度、欧氏距离和内积等，
向量检索速度快，
可以快速找到语义相似的语句。

生成过程则将检索到的数据与用户输入整合，
形成最终的提示词，
提供大语言模型以生成输出。

典型的复合了向量检索和BM25检索的RAG流程如图\ref{fig:复合检索RAG}所示。

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.9\textwidth]{复合检索RAG.png}
	\caption{复合检索RAG}
	\label{fig:复合检索RAG}
\end{figure}

RAG 的效果相比纯粹使用 LLM 有所提升，
但是对于用于静态分析工具评估测试集来说，
仍然需要进一步验证和确保结果的正确性。
为此 RAG 可以和责任链模式（Chain of Responsibility，COR）一起使用
其原理如图\ref{fig:责任链}所示。
COR 是一种通用行为设计模式，
允许请求沿着处理者链进行发送，
收到请求后，
每个处理者均可对请求进行处理，
或将其传递给链上的下个处理者。
COR 常见的应用方式是创建一系列定制的校验方法，
让某个对象一次经过这些校验方法，
以检验对象的符合要求的程度。

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.9\textwidth]{责任链.png}
	\caption{基本的责任链模式}
	\label{fig:责任链}
\end{figure}

本小节从测试集拓展的目的出发，
介绍了生成式人工智能的基本原理以及有何优势，
RAG可以看作当前应用人工智能领域用于生成的法宝，
结合COR等用于校验的软件设计模式，
可以为静态分析评估测试集拓展所用。

\section{模块化和容器化}

经过前文的介绍，
静态分析工具自动化评估系统需要的技术包含多个方面，
实际运行评估、管理测试集、拓展测试集、展示测试结果
各自都有独立的实现环境和方法，
并且需要建立在多样的生产环境中，
为此，模块化设计方法和容器化技术不可或缺。

模块化设计，旨在于将一个系统细分为许多小单元，
称为模组（module）或模块（block），
可以独立的于不同的系统中建立与使用。
模块化设计的特征为将功能切分为抽象的、可扩充的、可重复使用的模块；
模块需严格使用定义明确的模块化接口，
并以行业间标准作为接口规范。
模块化设计通常使用主程序、子程序和子过程等架构
将软体的主要结构和流程描述出来，
而非一般程式的编写──逐条输入电脑程式和指令。

容器化是一种软件打包和部署技术，
它将应用程序代码及其所有依赖项封装到一个标准化的、
可移植的“容器”中，
使应用能在任何环境（开发、测试、生产）中一致地运行。
其中容器（Container）指的是包含应用及其运行环境的独立软件包，
容器镜像 (Image)指的是容器的蓝图或模板，包含了创建容器所需的一切文件，
容器引擎 (Engine)指如Docker等用于创建、运行和管理容器的平台。

容器可以共享主机的操作系统内核，比虚拟机更轻量、高效，
实现“一次构建，随处运行”，
它极大简化了应用开发、测试和部署，
非常适合静态分析评估这样需要多种功能集成，
且功能之间比较灵活的系统。

本节介绍了模块化设计和容器化技术，
为本文目标系统的设计和实现提供了基本的技术路线。

总结本章，
从\tc~静态分析工具的分类、原理，
到静态分析工具的评估指标和流程，
到一些本文系统可以用得到的技术，
本章提供了一个基本的技术共识，
本文后续的问题建模、
系统设计和实现都基于这些技术成果。